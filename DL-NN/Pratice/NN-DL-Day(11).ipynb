{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[{"file_id":"1_1FwdH5EI3hhp6gfp1hYZOmss70JlQbR","timestamp":1701523835890}],"gpuType":"T4"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","source":["1) Fake news detection."],"metadata":{"id":"nSYLDc5r-c_D"}},{"cell_type":"code","source":["# Import necessary libraries\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder\n","from keras.preprocessing.text import Tokenizer\n","from keras.preprocessing.sequence import pad_sequences\n","from keras.models import Sequential\n","from keras.layers import Embedding, LSTM, Dense\n","\n","# Load your dataset\n","# Assuming you have a dataset with 'text' and 'label' columns\n","# 'text' contains the news articles, and 'label' contains the class (fake or real)\n","df = pd.read_csv('/content/FakeNewsNet.csv')\n","\n","# Preprocess the data\n","X = df['title'].values\n","y = df['real'].values\n","\n","# Convert labels to numerical values\n","le = LabelEncoder()\n","y = le.fit_transform(y)\n","\n","# Split the data into training and testing sets\n","X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n","\n","# Tokenize and pad sequences\n","max_words = 10000  # adjust based on your dataset\n","max_len = 100  # adjust based on the average length of your text\n","\n","tokenizer = Tokenizer(num_words=max_words)\n","tokenizer.fit_on_texts(X_train)\n","X_train_seq = tokenizer.texts_to_sequences(X_train)\n","X_test_seq = tokenizer.texts_to_sequences(X_test)\n","\n","X_train_pad = pad_sequences(X_train_seq, maxlen=max_len)\n","X_test_pad = pad_sequences(X_test_seq, maxlen=max_len)\n","\n","# Build the LSTM model\n","embedding_dim = 100  # adjust based on your dataset\n","model = Sequential()\n","model.add(Embedding(max_words, embedding_dim, input_length=max_len))\n","model.add(LSTM(100))\n","model.add(Dense(1, activation='sigmoid'))\n","\n","# Compile the model\n","model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n","\n","# Train the model\n","model.fit(X_train_pad, y_train, epochs=5, batch_size=32, validation_split=0.2)\n","\n","# Evaluate the model\n","accuracy = model.evaluate(X_test_pad, y_test)[1]\n","print(f'Accuracy: {accuracy}')\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"IG-EcEBvF8_b","executionInfo":{"status":"ok","timestamp":1699517227039,"user_tz":-330,"elapsed":272736,"user":{"displayName":"Mainak Ghosh","userId":"18317525661408114730"}},"outputId":"b093dcab-57ee-47da-d0fe-1949a3de92a8"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Epoch 1/5\n","464/464 [==============================] - 55s 112ms/step - loss: 0.4301 - accuracy: 0.8131 - val_loss: 0.3844 - val_accuracy: 0.8346\n","Epoch 2/5\n","464/464 [==============================] - 49s 105ms/step - loss: 0.2734 - accuracy: 0.8872 - val_loss: 0.4047 - val_accuracy: 0.8308\n","Epoch 3/5\n","464/464 [==============================] - 49s 105ms/step - loss: 0.1845 - accuracy: 0.9290 - val_loss: 0.5019 - val_accuracy: 0.8219\n","Epoch 4/5\n","464/464 [==============================] - 51s 111ms/step - loss: 0.1203 - accuracy: 0.9557 - val_loss: 0.5275 - val_accuracy: 0.8120\n","Epoch 5/5\n","464/464 [==============================] - 51s 110ms/step - loss: 0.0860 - accuracy: 0.9665 - val_loss: 0.6212 - val_accuracy: 0.8214\n","145/145 [==============================] - 4s 25ms/step - loss: 0.6412 - accuracy: 0.8129\n","Accuracy: 0.8129310607910156\n"]}]}]}